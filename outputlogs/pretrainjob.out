2022-05-07 11:48:34,293 - INFO - allennlp.common.params - udify_replace = ['dataset_reader.token_indexers', 'model.text_field_embedder', 'model.encoder', 'model.decoders.xpos', 'model.decoders.deps.encoder', 'model.decoders.upos.encoder', 'model.decoders.feats.encoder', 'model.decoders.lemmas.encoder', 'trainer.learning_rate_scheduler', 'trainer.optimizer']
2022-05-07 11:48:34,295 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ['upos', 'xpos', 'feats', 'lemmas', '*tags', '*labels']
2022-05-07 11:48:34,348 - INFO - allennlp.common.params - random_seed = 1
2022-05-07 11:48:34,348 - INFO - allennlp.common.params - numpy_seed = 1
2022-05-07 11:48:34,348 - INFO - allennlp.common.params - pytorch_seed = 1
2022-05-07 11:48:34,427 - INFO - allennlp.common.checks - Pytorch version: 1.11.0+cu102
2022-05-07 11:48:34,429 - INFO - allennlp.common.params - evaluate_on_test = True
2022-05-07 11:48:34,430 - INFO - allennlp.common.params - validation_dataset_reader = None
2022-05-07 11:48:34,430 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'config/archive/bert-base-multilingual-cased/vocab.txt', 'type': 'udify-bert-pretrained', 'use_starting_offsets': True}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'udify_universal_dependencies', 'lazy': False} and extras set()
2022-05-07 11:48:34,430 - INFO - allennlp.common.params - dataset_reader.type = udify_universal_dependencies
2022-05-07 11:48:34,430 - INFO - allennlp.common.from_params - instantiating class <class 'udify.dataset_readers.universal_dependencies.UniversalDependenciesDatasetReader'> from params {'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'config/archive/bert-base-multilingual-cased/vocab.txt', 'type': 'udify-bert-pretrained', 'use_starting_offsets': True}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'lazy': False} and extras set()
2022-05-07 11:48:34,430 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'config/archive/bert-base-multilingual-cased/vocab.txt', 'type': 'udify-bert-pretrained', 'use_starting_offsets': True} and extras set()
2022-05-07 11:48:34,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = udify-bert-pretrained
2022-05-07 11:48:34,431 - INFO - allennlp.common.from_params - instantiating class <class 'udify.modules.bert_pretrained.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'config/archive/bert-base-multilingual-cased/vocab.txt', 'use_starting_offsets': True} and extras set()
2022-05-07 11:48:34,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = config/archive/bert-base-multilingual-cased/vocab.txt
2022-05-07 11:48:34,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2022-05-07 11:48:34,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2022-05-07 11:48:34,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2022-05-07 11:48:34,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2022-05-07 11:48:34,431 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = False
2022-05-07 11:48:34,432 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file config/archive/bert-base-multilingual-cased/vocab.txt
2022-05-07 11:48:34,652 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()
2022-05-07 11:48:34,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2022-05-07 11:48:34,653 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer'> from params {'lowercase_tokens': True} and extras set()
2022-05-07 11:48:34,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2022-05-07 11:48:34,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2022-05-07 11:48:34,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2022-05-07 11:48:34,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2022-05-07 11:48:34,653 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-05-07 11:48:34,654 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-05-07 11:48:34,654 - INFO - allennlp.common.params - train_data_path = data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-train.conllu
2022-05-07 11:48:34,654 - INFO - allennlp.training.util - Reading training data from data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-train.conllu
0it [00:00, ?it/s]
2022-05-07 11:48:34,656 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-train.conllu
2022-05-07 11:48:35,106 - WARNING - allennlp.data.fields.sequence_label_field - Your label namespace was 'upos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.
2022-05-07 11:48:35,107 - WARNING - allennlp.data.fields.sequence_label_field - Your label namespace was 'xpos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.
2022-05-07 11:48:35,107 - WARNING - allennlp.data.fields.sequence_label_field - Your label namespace was 'feats'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.
2022-05-07 11:48:35,107 - WARNING - allennlp.data.fields.sequence_label_field - Your label namespace was 'lemmas'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.
4874it [00:10, 487.35it/s]
9748it [00:20, 484.86it/s]
13304it [00:27, 481.82it/s]

2022-05-07 11:49:02,267 - INFO - allennlp.common.params - validation_data_path = data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-dev.conllu
2022-05-07 11:49:02,267 - INFO - allennlp.training.util - Reading validation data from data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-dev.conllu
0it [00:00, ?it/s]
2022-05-07 11:49:02,268 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-dev.conllu
1659it [00:03, 515.18it/s]

2022-05-07 11:49:05,488 - INFO - allennlp.common.params - test_data_path = data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-test.conllu
2022-05-07 11:49:05,488 - INFO - allennlp.training.util - Reading test data from data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-test.conllu
0it [00:00, ?it/s]
2022-05-07 11:49:05,489 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-test.conllu
1684it [00:03, 445.01it/s]

2022-05-07 11:49:09,294 - INFO - allennlp.training.trainer_pieces - From dataset instances, train, test, validation will be considered for vocabulary creation.
2022-05-07 11:49:09,294 - INFO - allennlp.common.params - vocabulary.type = None
2022-05-07 11:49:09,294 - INFO - allennlp.common.params - vocabulary.extend = False
2022-05-07 11:49:09,294 - INFO - allennlp.common.params - vocabulary.directory_path = data/vocab/expmix/vocabulary
2022-05-07 11:49:09,294 - INFO - allennlp.data.vocabulary - Loading Vocab from files instead of dataset.
2022-05-07 11:49:09,294 - INFO - allennlp.data.vocabulary - Loading token dictionary from data/vocab/expmix/vocabulary.
2022-05-07 11:49:10,398 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'layer_dropout': 0.1, 'mix_embedding': 12, 'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'dropout': 0.5, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'combine_layers': 'all', 'dropout': 0.15, 'layer_dropout': 0.1, 'pretrained_model': 'bert-base-multilingual-cased', 'requires_grad': True, 'type': 'udify-bert-pretrained'}}, 'type': 'udify_embedder'}, 'type': 'udify_model', 'dropout': 0.5, 'tasks': ['deps'], 'decoders': {'upos': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'task': 'upos', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'}, 'feats': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'feats', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'}, 'lemmas': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'lemmas', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'}, 'deps': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'pos_embed_dim': None, 'dropout': 0.5, 'type': 'udify_dependency_decoder', 'arc_representation_dim': 768, 'tag_representation_dim': 256}}, 'word_dropout': 0.2} and extras {'vocab'}
2022-05-07 11:49:10,398 - INFO - allennlp.common.params - model.type = udify_model
2022-05-07 11:49:10,399 - INFO - allennlp.common.from_params - instantiating class <class 'udify.models.udify_model.UdifyModel'> from params {'layer_dropout': 0.1, 'mix_embedding': 12, 'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'dropout': 0.5, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'combine_layers': 'all', 'dropout': 0.15, 'layer_dropout': 0.1, 'pretrained_model': 'bert-base-multilingual-cased', 'requires_grad': True, 'type': 'udify-bert-pretrained'}}, 'type': 'udify_embedder'}, 'dropout': 0.5, 'tasks': ['deps'], 'decoders': {'upos': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'task': 'upos', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'}, 'feats': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'feats', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'}, 'lemmas': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'lemmas', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'}, 'deps': {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'pos_embed_dim': None, 'dropout': 0.5, 'type': 'udify_dependency_decoder', 'arc_representation_dim': 768, 'tag_representation_dim': 256}}, 'word_dropout': 0.2} and extras {'vocab'}
2022-05-07 11:49:10,399 - INFO - allennlp.common.params - model.tasks = ['deps']
2022-05-07 11:49:10,400 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'dropout': 0.5, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'combine_layers': 'all', 'dropout': 0.15, 'layer_dropout': 0.1, 'pretrained_model': 'bert-base-multilingual-cased', 'requires_grad': True, 'type': 'udify-bert-pretrained'}}, 'type': 'udify_embedder'} and extras {'vocab'}
2022-05-07 11:49:10,400 - INFO - allennlp.common.params - model.text_field_embedder.type = udify_embedder
2022-05-07 11:49:10,400 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True
2022-05-07 11:49:10,400 - INFO - allennlp.common.params - model.text_field_embedder.dropout = 0.5
2022-05-07 11:49:10,400 - INFO - allennlp.common.params - model.text_field_embedder.output_dim = None
2022-05-07 11:49:10,400 - INFO - allennlp.common.params - model.text_field_embedder.sum_embeddings = None
2022-05-07 11:49:10,400 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'combine_layers': 'all', 'dropout': 0.15, 'layer_dropout': 0.1, 'pretrained_model': 'bert-base-multilingual-cased', 'requires_grad': True, 'type': 'udify-bert-pretrained'} and extras {'vocab'}
2022-05-07 11:49:10,400 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = udify-bert-pretrained
2022-05-07 11:49:10,400 - INFO - allennlp.common.from_params - instantiating class <class 'udify.modules.bert_pretrained.UdifyPretrainedBertEmbedder'> from params {'combine_layers': 'all', 'dropout': 0.15, 'layer_dropout': 0.1, 'pretrained_model': 'bert-base-multilingual-cased', 'requires_grad': True} and extras {'vocab'}
2022-05-07 11:49:10,401 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-multilingual-cased
2022-05-07 11:49:10,401 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = True
2022-05-07 11:49:10,401 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.dropout = 0.15
2022-05-07 11:49:10,401 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.layer_dropout = 0.1
2022-05-07 11:49:10,401 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.combine_layers = all
2022-05-07 11:49:10,881 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at /home/lcur1446/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9
2022-05-07 11:49:10,883 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /home/lcur1446/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /scratch/tmpl5gk442v
2022-05-07 11:49:20,095 - INFO - pytorch_pretrained_bert.modeling - Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

2022-05-07 11:49:24,314 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'input_dim': 768, 'type': 'pass_through'} and extras {'vocab'}
2022-05-07 11:49:24,314 - INFO - allennlp.common.params - model.encoder.type = pass_through
2022-05-07 11:49:24,314 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.pass_through_encoder.PassThroughEncoder'> from params {'input_dim': 768} and extras {'vocab'}
2022-05-07 11:49:24,314 - INFO - allennlp.common.params - model.encoder.input_dim = 768
2022-05-07 11:49:24,315 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'task': 'upos', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'} and extras {'vocab'}
2022-05-07 11:49:24,315 - INFO - allennlp.common.params - model.decoders.upos.type = udify_tag_decoder
2022-05-07 11:49:24,315 - INFO - allennlp.common.from_params - instantiating class <class 'udify.models.tag_decoder.TagDecoder'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'task': 'upos', 'label_smoothing': 0.03, 'dropout': 0.5} and extras {'vocab'}
2022-05-07 11:49:24,315 - INFO - allennlp.common.params - model.decoders.upos.task = upos
2022-05-07 11:49:24,315 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'input_dim': 768, 'type': 'pass_through'} and extras {'vocab'}
2022-05-07 11:49:24,315 - INFO - allennlp.common.params - model.decoders.upos.encoder.type = pass_through
2022-05-07 11:49:24,316 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.pass_through_encoder.PassThroughEncoder'> from params {'input_dim': 768} and extras {'vocab'}
2022-05-07 11:49:24,316 - INFO - allennlp.common.params - model.decoders.upos.encoder.input_dim = 768
2022-05-07 11:49:24,316 - INFO - allennlp.common.params - model.decoders.upos.label_smoothing = 0.03
2022-05-07 11:49:24,316 - INFO - allennlp.common.params - model.decoders.upos.dropout = 0.5
2022-05-07 11:49:24,316 - INFO - allennlp.common.params - model.decoders.upos.adaptive = False
2022-05-07 11:49:24,316 - INFO - allennlp.common.params - model.decoders.upos.features = None
2022-05-07 11:49:24,317 - INFO - allennlp.nn.initializers - Initializing parameters
2022-05-07 11:49:24,317 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-05-07 11:49:24,317 - INFO - allennlp.nn.initializers -    task_output._module.bias
2022-05-07 11:49:24,317 - INFO - allennlp.nn.initializers -    task_output._module.weight
2022-05-07 11:49:24,317 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'feats', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'} and extras {'vocab'}
2022-05-07 11:49:24,317 - INFO - allennlp.common.params - model.decoders.feats.type = udify_tag_decoder
2022-05-07 11:49:24,318 - INFO - allennlp.common.from_params - instantiating class <class 'udify.models.tag_decoder.TagDecoder'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'feats', 'label_smoothing': 0.03, 'dropout': 0.5} and extras {'vocab'}
2022-05-07 11:49:24,318 - INFO - allennlp.common.params - model.decoders.feats.task = feats
2022-05-07 11:49:24,318 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'input_dim': 768, 'type': 'pass_through'} and extras {'vocab'}
2022-05-07 11:49:24,318 - INFO - allennlp.common.params - model.decoders.feats.encoder.type = pass_through
2022-05-07 11:49:24,318 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.pass_through_encoder.PassThroughEncoder'> from params {'input_dim': 768} and extras {'vocab'}
2022-05-07 11:49:24,318 - INFO - allennlp.common.params - model.decoders.feats.encoder.input_dim = 768
2022-05-07 11:49:24,318 - INFO - allennlp.common.params - model.decoders.feats.label_smoothing = 0.03
2022-05-07 11:49:24,319 - INFO - allennlp.common.params - model.decoders.feats.dropout = 0.5
2022-05-07 11:49:24,319 - INFO - allennlp.common.params - model.decoders.feats.adaptive = True
2022-05-07 11:49:24,319 - INFO - allennlp.common.params - model.decoders.feats.features = None
2022-05-07 11:49:24,334 - INFO - allennlp.nn.initializers - Initializing parameters
2022-05-07 11:49:24,334 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-05-07 11:49:24,334 - INFO - allennlp.nn.initializers -    task_output.head.weight
2022-05-07 11:49:24,334 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2022-05-07 11:49:24,335 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2022-05-07 11:49:24,335 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2022-05-07 11:49:24,335 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2022-05-07 11:49:24,335 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'lemmas', 'label_smoothing': 0.03, 'dropout': 0.5, 'type': 'udify_tag_decoder'} and extras {'vocab'}
2022-05-07 11:49:24,335 - INFO - allennlp.common.params - model.decoders.lemmas.type = udify_tag_decoder
2022-05-07 11:49:24,335 - INFO - allennlp.common.from_params - instantiating class <class 'udify.models.tag_decoder.TagDecoder'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'adaptive': True, 'task': 'lemmas', 'label_smoothing': 0.03, 'dropout': 0.5} and extras {'vocab'}
2022-05-07 11:49:24,335 - INFO - allennlp.common.params - model.decoders.lemmas.task = lemmas
2022-05-07 11:49:24,335 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'input_dim': 768, 'type': 'pass_through'} and extras {'vocab'}
2022-05-07 11:49:24,336 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.type = pass_through
2022-05-07 11:49:24,336 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.pass_through_encoder.PassThroughEncoder'> from params {'input_dim': 768} and extras {'vocab'}
2022-05-07 11:49:24,336 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.input_dim = 768
2022-05-07 11:49:24,336 - INFO - allennlp.common.params - model.decoders.lemmas.label_smoothing = 0.03
2022-05-07 11:49:24,336 - INFO - allennlp.common.params - model.decoders.lemmas.dropout = 0.5
2022-05-07 11:49:24,336 - INFO - allennlp.common.params - model.decoders.lemmas.adaptive = True
2022-05-07 11:49:24,336 - INFO - allennlp.common.params - model.decoders.lemmas.features = None
2022-05-07 11:49:24,404 - INFO - allennlp.nn.initializers - Initializing parameters
2022-05-07 11:49:24,404 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-05-07 11:49:24,405 - INFO - allennlp.nn.initializers -    task_output.head.weight
2022-05-07 11:49:24,405 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2022-05-07 11:49:24,405 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2022-05-07 11:49:24,405 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2022-05-07 11:49:24,405 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2022-05-07 11:49:24,405 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'pos_embed_dim': None, 'dropout': 0.5, 'type': 'udify_dependency_decoder', 'arc_representation_dim': 768, 'tag_representation_dim': 256} and extras {'vocab'}
2022-05-07 11:49:24,405 - INFO - allennlp.common.params - model.decoders.deps.type = udify_dependency_decoder
2022-05-07 11:49:24,405 - INFO - allennlp.common.from_params - instantiating class <class 'udify.models.dependency_decoder.DependencyDecoder'> from params {'encoder': {'input_dim': 768, 'type': 'pass_through'}, 'pos_embed_dim': None, 'dropout': 0.5, 'arc_representation_dim': 768, 'tag_representation_dim': 256} and extras {'vocab'}
2022-05-07 11:49:24,406 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'input_dim': 768, 'type': 'pass_through'} and extras {'vocab'}
2022-05-07 11:49:24,406 - INFO - allennlp.common.params - model.decoders.deps.encoder.type = pass_through
2022-05-07 11:49:24,406 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.pass_through_encoder.PassThroughEncoder'> from params {'input_dim': 768} and extras {'vocab'}
2022-05-07 11:49:24,406 - INFO - allennlp.common.params - model.decoders.deps.encoder.input_dim = 768
2022-05-07 11:49:24,406 - INFO - allennlp.common.params - model.decoders.deps.tag_representation_dim = 256
2022-05-07 11:49:24,406 - INFO - allennlp.common.params - model.decoders.deps.arc_representation_dim = 768
2022-05-07 11:49:24,406 - INFO - allennlp.common.params - model.decoders.deps.pos_embed_dim = None
2022-05-07 11:49:24,406 - INFO - allennlp.common.params - model.decoders.deps.use_mst_decoding_for_validation = True
2022-05-07 11:49:24,406 - INFO - allennlp.common.params - model.decoders.deps.dropout = 0.5
2022-05-07 11:49:24,407 - INFO - allennlp.common.registrable - instantiating registered subclass elu of <class 'allennlp.nn.activations.Activation'>
2022-05-07 11:49:24,417 - INFO - allennlp.common.registrable - instantiating registered subclass linear of <class 'allennlp.nn.activations.Activation'>
2022-05-07 11:49:24,425 - INFO - allennlp.common.registrable - instantiating registered subclass elu of <class 'allennlp.nn.activations.Activation'>
2022-05-07 11:49:24,525 - INFO - udify.models.dependency_decoder - Found POS tags corresponding to the following punctuation : {}. Ignoring words with these POS tags for evaluation.
2022-05-07 11:49:24,525 - INFO - allennlp.nn.initializers - Initializing parameters
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    _head_sentinel
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    arc_attention._bias
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    arc_attention._weight_matrix
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    tag_bilinear.bias
2022-05-07 11:49:24,526 - INFO - allennlp.nn.initializers -    tag_bilinear.weight
2022-05-07 11:49:24,527 - INFO - allennlp.common.params - model.dropout = 0.5
2022-05-07 11:49:24,527 - INFO - allennlp.common.params - model.word_dropout = 0.2
2022-05-07 11:49:24,527 - INFO - allennlp.common.params - model.mix_embedding = 12
2022-05-07 11:49:24,527 - INFO - allennlp.common.params - model.layer_dropout = 0.1
2022-05-07 11:49:24,528 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file config/archive/bert-base-multilingual-cased/vocab.txt
2022-05-07 11:49:24,752 - INFO - allennlp.nn.initializers - Initializing parameters
2022-05-07 11:49:24,753 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-05-07 11:49:24,753 - INFO - allennlp.nn.initializers -    decoders.deps._head_sentinel
2022-05-07 11:49:24,753 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._bias
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._weight_matrix
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.bias
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.bias
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.head.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.0.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.1.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.0.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.1.weight
2022-05-07 11:49:24,754 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.head.weight
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.0.weight
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.1.weight
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.0.weight
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.1.weight
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.bias
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.weight
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.gamma
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.0
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.1
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.10
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.11
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.2
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.3
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.4
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.5
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.6
2022-05-07 11:49:24,755 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.7
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.8
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.9
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.gamma
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.0
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.1
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.10
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.11
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.2
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.3
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.4
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.5
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.6
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.7
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.8
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.9
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.gamma
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.0
2022-05-07 11:49:24,756 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.1
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.10
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.11
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.2
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.3
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.4
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.5
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.6
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.7
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.8
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.9
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.gamma
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.0
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.1
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.10
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.11
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.2
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.3
2022-05-07 11:49:24,757 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.4
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.5
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.6
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.7
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.8
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.9
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2022-05-07 11:49:24,758 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2022-05-07 11:49:24,759 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2022-05-07 11:49:24,760 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2022-05-07 11:49:24,761 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2022-05-07 11:49:24,762 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2022-05-07 11:49:24,763 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2022-05-07 11:49:24,764 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2022-05-07 11:49:24,765 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-05-07 11:49:24,766 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2022-05-07 11:49:24,767 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2022-05-07 11:49:24,768 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2022-05-07 11:49:24,769 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2022-05-07 11:49:24,772 - INFO - udify.models.udify_model - Total number of parameters: 195723932
2022-05-07 11:49:24,772 - INFO - udify.models.udify_model - Total number of trainable parameters: 195723932
2022-05-07 11:49:25,541 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'biggest_batch_first': True, 'type': 'bucket', 'sorting_keys': [['tokens', 'num_tokens']], 'batch_size': 16} and extras set()
2022-05-07 11:49:25,542 - INFO - allennlp.common.params - iterator.type = bucket
2022-05-07 11:49:25,542 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'biggest_batch_first': True, 'sorting_keys': [['tokens', 'num_tokens']], 'batch_size': 16} and extras set()
2022-05-07 11:49:25,542 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]
2022-05-07 11:49:25,542 - INFO - allennlp.common.params - iterator.padding_noise = 0.1
2022-05-07 11:49:25,542 - INFO - allennlp.common.params - iterator.biggest_batch_first = True
2022-05-07 11:49:25,542 - INFO - allennlp.common.params - iterator.batch_size = 16
2022-05-07 11:49:25,542 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2022-05-07 11:49:25,542 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None
2022-05-07 11:49:25,543 - INFO - allennlp.common.params - iterator.cache_instances = False
2022-05-07 11:49:25,543 - INFO - allennlp.common.params - iterator.track_epoch = False
2022-05-07 11:49:25,543 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2022-05-07 11:49:25,543 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False
2022-05-07 11:49:25,543 - INFO - allennlp.common.params - validation_iterator = None
2022-05-07 11:49:25,543 - INFO - allennlp.common.params - trainer.no_grad = ()
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2022-05-07 11:49:25,546 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2022-05-07 11:49:25,547 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2022-05-07 11:49:25,548 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2022-05-07 11:49:25,549 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2022-05-07 11:49:25,550 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2022-05-07 11:49:25,551 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2022-05-07 11:49:25,552 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2022-05-07 11:49:25,553 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-05-07 11:49:25,554 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2022-05-07 11:49:25,555 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2022-05-07 11:49:25,556 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.upos.task_output._module.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.upos.task_output._module.bias
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.feats.task_output.head.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.feats.task_output.tail.0.0.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.feats.task_output.tail.0.1.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.feats.task_output.tail.1.0.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.feats.task_output.tail.1.1.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.lemmas.task_output.head.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.lemmas.task_output.tail.0.0.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.lemmas.task_output.tail.0.1.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.lemmas.task_output.tail.1.0.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.lemmas.task_output.tail.1.1.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.deps._head_sentinel
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.deps.head_arc_feedforward._linear_layers.0.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.deps.head_arc_feedforward._linear_layers.0.bias
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.deps.child_arc_feedforward._linear_layers.0.weight
2022-05-07 11:49:25,557 - INFO - allennlp.training.trainer_pieces - decoders.deps.child_arc_feedforward._linear_layers.0.bias
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.arc_attention._weight_matrix
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.arc_attention._bias
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.head_tag_feedforward._linear_layers.0.weight
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.head_tag_feedforward._linear_layers.0.bias
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.child_tag_feedforward._linear_layers.0.weight
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.child_tag_feedforward._linear_layers.0.bias
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.tag_bilinear.weight
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - decoders.deps.tag_bilinear.bias
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.gamma
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.0
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.1
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.2
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.3
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.4
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.5
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.6
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.7
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.8
2022-05-07 11:49:25,558 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.9
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.10
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.upos.scalar_parameters.11
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.gamma
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.0
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.1
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.2
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.3
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.4
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.5
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.6
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.7
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.8
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.9
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.10
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.feats.scalar_parameters.11
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.gamma
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.0
2022-05-07 11:49:25,559 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.1
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.2
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.3
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.4
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.5
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.6
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.7
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.8
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.9
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.10
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.lemmas.scalar_parameters.11
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.gamma
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.0
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.1
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.2
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.3
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.4
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.5
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.6
2022-05-07 11:49:25,560 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.7
2022-05-07 11:49:25,561 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.8
2022-05-07 11:49:25,561 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.9
2022-05-07 11:49:25,561 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.10
2022-05-07 11:49:25,561 - INFO - allennlp.training.trainer_pieces - scalar_mix.deps.scalar_parameters.11
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.patience = 40
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.validation_metric = +.run/.sum
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.shuffle = True
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.num_epochs = 5
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.grad_norm = 5
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.grad_clipping = 10
2022-05-07 11:49:25,561 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-05-07 11:49:29,344 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam
2022-05-07 11:49:29,344 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2022-05-07 11:49:29,344 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2022-05-07 11:49:29,344 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2022-05-07 11:49:29,344 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2022-05-07 11:49:29,351 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-05-07 11:49:29,351 - INFO - allennlp.training.optimizers - Group 0: ['text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias'], {}
2022-05-07 11:49:29,352 - INFO - allennlp.training.optimizers - Group 1: ['scalar_mix.lemmas.scalar_parameters.9', 'scalar_mix.upos.scalar_parameters.3', 'decoders.deps._head_sentinel', 'text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight', 'decoders.upos.task_output._module.bias', 'decoders.deps.child_arc_feedforward._linear_layers.0.bias', 'scalar_mix.upos.scalar_parameters.7', 'decoders.lemmas.task_output.tail.0.0.weight', 'decoders.feats.task_output.tail.1.0.weight', 'decoders.deps.head_arc_feedforward._linear_layers.0.weight', 'decoders.feats.task_output.tail.0.1.weight', 'decoders.lemmas.task_output.tail.0.1.weight', 'scalar_mix.upos.scalar_parameters.4', 'scalar_mix.deps.scalar_parameters.8', 'scalar_mix.deps.scalar_parameters.0', 'scalar_mix.upos.scalar_parameters.5', 'scalar_mix.upos.scalar_parameters.2', 'scalar_mix.feats.scalar_parameters.7', 'scalar_mix.lemmas.scalar_parameters.7', 'scalar_mix.lemmas.scalar_parameters.10', 'decoders.deps.arc_attention._bias', 'scalar_mix.upos.gamma', 'decoders.feats.task_output.tail.1.1.weight', 'decoders.deps.child_tag_feedforward._linear_layers.0.bias', 'scalar_mix.feats.scalar_parameters.4', 'decoders.deps.arc_attention._weight_matrix', 'scalar_mix.feats.scalar_parameters.1', 'scalar_mix.feats.scalar_parameters.5', 'scalar_mix.feats.scalar_parameters.11', 'scalar_mix.upos.scalar_parameters.8', 'scalar_mix.deps.scalar_parameters.1', 'scalar_mix.feats.scalar_parameters.8', 'scalar_mix.deps.scalar_parameters.11', 'scalar_mix.deps.scalar_parameters.2', 'scalar_mix.feats.scalar_parameters.3', 'scalar_mix.feats.scalar_parameters.9', 'decoders.deps.tag_bilinear.weight', 'scalar_mix.deps.scalar_parameters.4', 'scalar_mix.lemmas.scalar_parameters.5', 'decoders.lemmas.task_output.tail.1.1.weight', 'decoders.upos.task_output._module.weight', 'decoders.feats.task_output.tail.0.0.weight', 'scalar_mix.deps.scalar_parameters.5', 'scalar_mix.upos.scalar_parameters.1', 'scalar_mix.deps.scalar_parameters.6', 'scalar_mix.upos.scalar_parameters.10', 'scalar_mix.lemmas.scalar_parameters.8', 'scalar_mix.upos.scalar_parameters.0', 'scalar_mix.upos.scalar_parameters.6', 'scalar_mix.upos.scalar_parameters.11', 'scalar_mix.deps.scalar_parameters.10', 'scalar_mix.lemmas.gamma', 'decoders.deps.child_tag_feedforward._linear_layers.0.weight', 'text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias', 'scalar_mix.deps.scalar_parameters.3', 'scalar_mix.feats.scalar_parameters.10', 'scalar_mix.upos.scalar_parameters.9', 'scalar_mix.lemmas.scalar_parameters.6', 'scalar_mix.deps.scalar_parameters.9', 'scalar_mix.lemmas.scalar_parameters.11', 'decoders.lemmas.task_output.tail.1.0.weight', 'decoders.deps.head_tag_feedforward._linear_layers.0.weight', 'decoders.deps.head_tag_feedforward._linear_layers.0.bias', 'scalar_mix.feats.gamma', 'scalar_mix.lemmas.scalar_parameters.0', 'scalar_mix.lemmas.scalar_parameters.1', 'scalar_mix.deps.scalar_parameters.7', 'scalar_mix.feats.scalar_parameters.2', 'scalar_mix.lemmas.scalar_parameters.4', 'decoders.feats.task_output.head.weight', 'decoders.deps.child_arc_feedforward._linear_layers.0.weight', 'scalar_mix.lemmas.scalar_parameters.2', 'scalar_mix.feats.scalar_parameters.0', 'scalar_mix.lemmas.scalar_parameters.3', 'decoders.lemmas.task_output.head.weight', 'decoders.deps.head_arc_feedforward._linear_layers.0.bias', 'decoders.deps.tag_bilinear.bias', 'scalar_mix.deps.gamma', 'scalar_mix.feats.scalar_parameters.6'], {}
2022-05-07 11:49:29,352 - INFO - allennlp.training.optimizers - Group 2: [], {}
2022-05-07 11:49:29,352 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  ^text_field_embedder.*._scalar_mix not match any parameter name
2022-05-07 11:49:29,352 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  ^shared_encoder not match any parameter name
2022-05-07 11:49:29,352 - INFO - allennlp.training.optimizers - Number of trainable parameters: 195723932
2022-05-07 11:49:29,352 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True
2022-05-07 11:49:29,352 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2022-05-07 11:49:29,352 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2022-05-07 11:49:29,353 - INFO - allennlp.common.params - trainer.optimizer.b1 = 0.9
2022-05-07 11:49:29,353 - INFO - allennlp.common.params - trainer.optimizer.b2 = 0.99
2022-05-07 11:49:29,353 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001
2022-05-07 11:49:29,353 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.01
2022-05-07 11:49:29,353 - INFO - allennlp.common.registrable - instantiating registered subclass bert_adam of <class 'allennlp.training.optimizers.Optimizer'>
2022-05-07 11:49:29,353 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = ulmfit_sqrt
2022-05-07 11:49:29,354 - INFO - allennlp.common.registrable - instantiating registered subclass ulmfit_sqrt of <class 'allennlp.training.learning_rate_schedulers.learning_rate_scheduler.LearningRateScheduler'>
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.04
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = True
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.factor = 5
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = True
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.model_size = 1
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.start_step = 392
2022-05-07 11:49:29,354 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 392
2022-05-07 11:49:29,355 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing. Training only the top 1 layers.
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 1
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.model_save_interval = None
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.summary_interval = 100
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.histogram_interval = None
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = False
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.should_log_learning_rate = True
2022-05-07 11:49:29,355 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2022-05-07 11:49:29,368 - INFO - allennlp.training.trainer - Beginning training.
2022-05-07 11:49:29,368 - INFO - allennlp.training.trainer - Epoch 0/4
2022-05-07 11:49:29,368 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4258.136
2022-05-07 11:49:29,491 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1473
2022-05-07 11:49:29,499 - INFO - allennlp.training.trainer - Training
  0%|          | 0/832 [00:00<?, ?it/s]
/home/lcur1446/.local/lib/python3.8/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
.run/deps/UAS: 0.0866, .run/deps/LAS: 0.0196, .run/deps/UEM: 0.0000, .run/deps/LEM: 0.0000, .run/.sum: 0.1062, loss: 28.2503 ||:   2%|1         | 13/832 [00:10<10:30,  1.30it/s]
.run/deps/UAS: 0.2008, .run/deps/LAS: 0.1131, .run/deps/UEM: 0.0000, .run/deps/LEM: 0.0000, .run/.sum: 0.3139, loss: 20.5291 ||:   8%|7         | 66/832 [00:20<03:30,  3.65it/s]
.run/deps/UAS: 0.2339, .run/deps/LAS: 0.1425, .run/deps/UEM: 0.0005, .run/deps/LEM: 0.0005, .run/.sum: 0.3763, loss: 16.2720 ||:  14%|#4        | 120/832 [00:30<02:41,  4.41it/s]
.run/deps/UAS: 0.2534, .run/deps/LAS: 0.1600, .run/deps/UEM: 0.0004, .run/deps/LEM: 0.0004, .run/.sum: 0.4134, loss: 13.3726 ||:  21%|##1       | 177/832 [00:40<02:13,  4.91it/s]
.run/deps/UAS: 0.2713, .run/deps/LAS: 0.1760, .run/deps/UEM: 0.0003, .run/deps/LEM: 0.0003, .run/.sum: 0.4472, loss: 11.3726 ||:  28%|##8       | 235/832 [00:50<01:54,  5.21it/s]
.run/deps/UAS: 0.2853, .run/deps/LAS: 0.1900, .run/deps/UEM: 0.0004, .run/deps/LEM: 0.0002, .run/.sum: 0.4753, loss: 9.9508 ||:  35%|###5      | 294/832 [01:00<01:39,  5.40it/s] 
.run/deps/UAS: 0.2996, .run/deps/LAS: 0.2031, .run/deps/UEM: 0.0004, .run/deps/LEM: 0.0002, .run/.sum: 0.5027, loss: 8.9445 ||:  42%|####2     | 352/832 [01:10<01:27,  5.46it/s]
.run/deps/UAS: 0.3077, .run/deps/LAS: 0.2112, .run/deps/UEM: 0.0009, .run/deps/LEM: 0.0003, .run/.sum: 0.5189, loss: 8.2101 ||:  49%|####9     | 408/832 [01:22<01:19,  5.33it/s]
.run/deps/UAS: 0.3180, .run/deps/LAS: 0.2215, .run/deps/UEM: 0.0008, .run/deps/LEM: 0.0003, .run/.sum: 0.5395, loss: 7.6058 ||:  56%|#####5    | 465/832 [01:32<01:07,  5.41it/s]
.run/deps/UAS: 0.3277, .run/deps/LAS: 0.2308, .run/deps/UEM: 0.0016, .run/deps/LEM: 0.0002, .run/.sum: 0.5585, loss: 7.1158 ||:  63%|######2   | 521/832 [01:42<00:57,  5.42it/s]
.run/deps/UAS: 0.3364, .run/deps/LAS: 0.2398, .run/deps/UEM: 0.0014, .run/deps/LEM: 0.0002, .run/.sum: 0.5762, loss: 6.7142 ||:  69%|######9   | 576/832 [01:53<00:47,  5.33it/s]
.run/deps/UAS: 0.3445, .run/deps/LAS: 0.2481, .run/deps/UEM: 0.0016, .run/deps/LEM: 0.0003, .run/.sum: 0.5926, loss: 6.3885 ||:  75%|#######5  | 628/832 [02:03<00:38,  5.26it/s]
.run/deps/UAS: 0.3526, .run/deps/LAS: 0.2561, .run/deps/UEM: 0.0019, .run/deps/LEM: 0.0005, .run/.sum: 0.6087, loss: 6.1085 ||:  82%|########1 | 680/832 [02:13<00:29,  5.24it/s]
.run/deps/UAS: 0.3590, .run/deps/LAS: 0.2629, .run/deps/UEM: 0.0020, .run/deps/LEM: 0.0004, .run/.sum: 0.6219, loss: 5.8647 ||:  88%|########7 | 732/832 [02:23<00:19,  5.17it/s]
.run/deps/UAS: 0.3656, .run/deps/LAS: 0.2697, .run/deps/UEM: 0.0019, .run/deps/LEM: 0.0004, .run/.sum: 0.6353, loss: 5.6549 ||:  94%|#########4| 783/832 [02:34<00:09,  5.04it/s]
.run/deps/UAS: 0.3719, .run/deps/LAS: 0.2761, .run/deps/UEM: 0.0021, .run/deps/LEM: 0.0004, .run/.sum: 0.6480, loss: 5.4695 ||: 100%|##########| 832/832 [02:43<00:00,  5.08it/s]

2022-05-07 11:52:13,125 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/104 [00:00<?, ?it/s]
.run/deps/UAS: 0.7336, .run/deps/LAS: 0.6640, .run/deps/UEM: 0.0579, .run/deps/LEM: 0.0196, .run/.sum: 1.3977, loss: 1.3660 ||:  74%|#######4  | 77/104 [00:10<00:03,  7.62it/s]
.run/deps/UAS: 0.7164, .run/deps/LAS: 0.6472, .run/deps/UEM: 0.0428, .run/deps/LEM: 0.0145, .run/.sum: 1.3637, loss: 1.4345 ||: 100%|##########| 104/104 [00:17<00:00,  5.89it/s]

2022-05-07 11:52:30,773 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2022-05-07 11:52:30,775 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS   |     0.372  |     0.716
2022-05-07 11:52:30,776 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4258.136  |       N/A
2022-05-07 11:52:30,776 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM   |     0.002  |     0.043
2022-05-07 11:52:30,776 - INFO - allennlp.training.tensorboard_writer - loss            |     5.470  |     1.434
2022-05-07 11:52:30,776 - INFO - allennlp.training.tensorboard_writer - .run/.sum       |     0.648  |     1.364
2022-05-07 11:52:30,777 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS   |     0.276  |     0.647
2022-05-07 11:52:30,777 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  1473.000  |       N/A
2022-05-07 11:52:30,777 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM   |     0.000  |     0.014
2022-05-07 11:52:30,781 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2022-05-07 11:52:33,616 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/hindi_pretrained/2022.05.07_11.48.34/best.th'.
2022-05-07 11:52:35,696 - INFO - allennlp.training.trainer - Epoch duration: 0:03:06.328300
2022-05-07 11:52:35,698 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:12:25
2022-05-07 11:52:35,698 - INFO - allennlp.training.trainer - Epoch 1/4
2022-05-07 11:52:35,698 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4295.348
2022-05-07 11:52:35,810 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 2527
2022-05-07 11:52:35,818 - INFO - allennlp.training.trainer - Training
  0%|          | 0/832 [00:00<?, ?it/s]
.run/deps/UAS: 0.4715, .run/deps/LAS: 0.3820, .run/deps/UEM: 0.0053, .run/deps/LEM: 0.0027, .run/.sum: 0.8535, loss: 2.5003 ||:   3%|2         | 24/832 [00:10<05:38,  2.39it/s]
.run/deps/UAS: 0.4997, .run/deps/LAS: 0.4058, .run/deps/UEM: 0.0026, .run/deps/LEM: 0.0013, .run/.sum: 0.9055, loss: 2.4035 ||:   6%|5         | 49/832 [00:20<05:19,  2.45it/s]
.run/deps/UAS: 0.5243, .run/deps/LAS: 0.4304, .run/deps/UEM: 0.0082, .run/deps/LEM: 0.0033, .run/.sum: 0.9547, loss: 2.2879 ||:   9%|9         | 77/832 [00:30<04:52,  2.58it/s]
.run/deps/UAS: 0.5362, .run/deps/LAS: 0.4411, .run/deps/UEM: 0.0059, .run/deps/LEM: 0.0024, .run/.sum: 0.9772, loss: 2.2371 ||:  13%|#2        | 106/832 [00:40<04:30,  2.68it/s]
.run/deps/UAS: 0.5405, .run/deps/LAS: 0.4442, .run/deps/UEM: 0.0065, .run/deps/LEM: 0.0023, .run/.sum: 0.9847, loss: 2.2067 ||:  16%|#6        | 135/832 [00:51<04:18,  2.70it/s]
.run/deps/UAS: 0.5498, .run/deps/LAS: 0.4528, .run/deps/UEM: 0.0057, .run/deps/LEM: 0.0019, .run/.sum: 1.0026, loss: 2.1740 ||:  20%|#9        | 164/832 [01:01<04:03,  2.75it/s]
.run/deps/UAS: 0.5574, .run/deps/LAS: 0.4599, .run/deps/UEM: 0.0075, .run/deps/LEM: 0.0019, .run/.sum: 1.0174, loss: 2.1391 ||:  23%|##3       | 193/832 [01:12<03:57,  2.69it/s]
.run/deps/UAS: 0.5647, .run/deps/LAS: 0.4663, .run/deps/UEM: 0.0094, .run/deps/LEM: 0.0017, .run/.sum: 1.0310, loss: 2.1113 ||:  26%|##6       | 220/832 [01:22<03:48,  2.67it/s]
.run/deps/UAS: 0.5703, .run/deps/LAS: 0.4722, .run/deps/UEM: 0.0099, .run/deps/LEM: 0.0015, .run/.sum: 1.0426, loss: 2.0864 ||:  30%|##9       | 247/832 [01:33<03:42,  2.62it/s]
.run/deps/UAS: 0.5775, .run/deps/LAS: 0.4788, .run/deps/UEM: 0.0107, .run/deps/LEM: 0.0016, .run/.sum: 1.0563, loss: 2.0543 ||:  33%|###2      | 274/832 [01:43<03:30,  2.65it/s]
.run/deps/UAS: 0.5854, .run/deps/LAS: 0.4866, .run/deps/UEM: 0.0107, .run/deps/LEM: 0.0021, .run/.sum: 1.0719, loss: 2.0252 ||:  37%|###6      | 305/832 [01:54<03:11,  2.75it/s]
.run/deps/UAS: 0.5893, .run/deps/LAS: 0.4903, .run/deps/UEM: 0.0121, .run/deps/LEM: 0.0022, .run/.sum: 1.0796, loss: 2.0095 ||:  40%|####      | 335/832 [02:04<02:59,  2.77it/s]
.run/deps/UAS: 0.5945, .run/deps/LAS: 0.4954, .run/deps/UEM: 0.0135, .run/deps/LEM: 0.0024, .run/.sum: 1.0899, loss: 1.9843 ||:  44%|####3     | 365/832 [02:14<02:44,  2.84it/s]
.run/deps/UAS: 0.5985, .run/deps/LAS: 0.4995, .run/deps/UEM: 0.0154, .run/deps/LEM: 0.0029, .run/.sum: 1.0980, loss: 1.9704 ||:  47%|####7     | 395/832 [02:25<02:37,  2.78it/s]
.run/deps/UAS: 0.6031, .run/deps/LAS: 0.5042, .run/deps/UEM: 0.0165, .run/deps/LEM: 0.0032, .run/.sum: 1.1072, loss: 1.9500 ||:  51%|#####1    | 425/832 [02:36<02:24,  2.82it/s]
.run/deps/UAS: 0.6079, .run/deps/LAS: 0.5092, .run/deps/UEM: 0.0172, .run/deps/LEM: 0.0034, .run/.sum: 1.1171, loss: 1.9286 ||:  55%|#####4    | 455/832 [02:46<02:12,  2.84it/s]
.run/deps/UAS: 0.6130, .run/deps/LAS: 0.5143, .run/deps/UEM: 0.0175, .run/deps/LEM: 0.0035, .run/.sum: 1.1273, loss: 1.9076 ||:  58%|#####8    | 485/832 [02:56<02:00,  2.87it/s]
.run/deps/UAS: 0.6169, .run/deps/LAS: 0.5183, .run/deps/UEM: 0.0176, .run/deps/LEM: 0.0034, .run/.sum: 1.1351, loss: 1.8922 ||:  62%|######1   | 515/832 [03:07<01:51,  2.83it/s]
.run/deps/UAS: 0.6203, .run/deps/LAS: 0.5218, .run/deps/UEM: 0.0199, .run/deps/LEM: 0.0045, .run/.sum: 1.1420, loss: 1.8743 ||:  65%|######5   | 543/832 [03:18<01:44,  2.76it/s]
.run/deps/UAS: 0.6238, .run/deps/LAS: 0.5253, .run/deps/UEM: 0.0221, .run/deps/LEM: 0.0052, .run/.sum: 1.1490, loss: 1.8591 ||:  69%|######8   | 570/832 [03:28<01:36,  2.73it/s]
.run/deps/UAS: 0.6271, .run/deps/LAS: 0.5285, .run/deps/UEM: 0.0226, .run/deps/LEM: 0.0053, .run/.sum: 1.1556, loss: 1.8427 ||:  72%|#######2  | 600/832 [03:39<01:23,  2.77it/s]
.run/deps/UAS: 0.6300, .run/deps/LAS: 0.5315, .run/deps/UEM: 0.0232, .run/deps/LEM: 0.0055, .run/.sum: 1.1615, loss: 1.8310 ||:  76%|#######5  | 629/832 [03:49<01:13,  2.75it/s]
.run/deps/UAS: 0.6331, .run/deps/LAS: 0.5349, .run/deps/UEM: 0.0248, .run/deps/LEM: 0.0059, .run/.sum: 1.1680, loss: 1.8162 ||:  79%|#######9  | 658/832 [04:00<01:02,  2.77it/s]
.run/deps/UAS: 0.6360, .run/deps/LAS: 0.5379, .run/deps/UEM: 0.0253, .run/deps/LEM: 0.0058, .run/.sum: 1.1739, loss: 1.8061 ||:  83%|########2 | 687/832 [04:10<00:52,  2.79it/s]
.run/deps/UAS: 0.6387, .run/deps/LAS: 0.5409, .run/deps/UEM: 0.0268, .run/deps/LEM: 0.0064, .run/.sum: 1.1796, loss: 1.7942 ||:  86%|########6 | 716/832 [04:20<00:41,  2.79it/s]
.run/deps/UAS: 0.6408, .run/deps/LAS: 0.5429, .run/deps/UEM: 0.0290, .run/deps/LEM: 0.0067, .run/.sum: 1.1837, loss: 1.7854 ||:  90%|########9 | 745/832 [04:31<00:31,  2.80it/s]
.run/deps/UAS: 0.6435, .run/deps/LAS: 0.5459, .run/deps/UEM: 0.0300, .run/deps/LEM: 0.0069, .run/.sum: 1.1895, loss: 1.7713 ||:  93%|#########3| 774/832 [04:41<00:20,  2.82it/s]
.run/deps/UAS: 0.6457, .run/deps/LAS: 0.5485, .run/deps/UEM: 0.0319, .run/deps/LEM: 0.0078, .run/.sum: 1.1942, loss: 1.7603 ||:  97%|#########6| 803/832 [04:51<00:10,  2.83it/s]
.run/deps/UAS: 0.6484, .run/deps/LAS: 0.5516, .run/deps/UEM: 0.0319, .run/deps/LEM: 0.0077, .run/.sum: 1.2000, loss: 1.7492 ||: 100%|##########| 832/832 [05:01<00:00,  2.83it/s]
.run/deps/UAS: 0.6484, .run/deps/LAS: 0.5516, .run/deps/UEM: 0.0319, .run/deps/LEM: 0.0077, .run/.sum: 1.2000, loss: 1.7492 ||: 100%|##########| 832/832 [05:01<00:00,  2.76it/s]

2022-05-07 11:57:37,351 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/104 [00:00<?, ?it/s]
.run/deps/UAS: 0.8771, .run/deps/LAS: 0.8193, .run/deps/UEM: 0.2674, .run/deps/LEM: 0.1262, .run/.sum: 1.6964, loss: 0.6756 ||:  81%|########  | 84/104 [00:10<00:02,  8.34it/s]
.run/deps/UAS: 0.8687, .run/deps/LAS: 0.8105, .run/deps/UEM: 0.2206, .run/deps/LEM: 0.1031, .run/.sum: 1.6792, loss: 0.7036 ||: 100%|##########| 104/104 [00:15<00:00,  6.77it/s]

2022-05-07 11:57:52,718 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2022-05-07 11:57:52,719 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS   |     0.648  |     0.869
2022-05-07 11:57:52,720 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4295.348  |       N/A
2022-05-07 11:57:52,721 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM   |     0.032  |     0.221
2022-05-07 11:57:52,722 - INFO - allennlp.training.tensorboard_writer - loss            |     1.749  |     0.704
2022-05-07 11:57:52,722 - INFO - allennlp.training.tensorboard_writer - .run/.sum       |     1.200  |     1.679
2022-05-07 11:57:52,723 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS   |     0.552  |     0.810
2022-05-07 11:57:52,724 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  2527.000  |       N/A
2022-05-07 11:57:52,724 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM   |     0.008  |     0.103
2022-05-07 11:57:52,727 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2022-05-07 11:58:00,101 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/hindi_pretrained/2022.05.07_11.48.34/best.th'.
2022-05-07 11:58:02,187 - INFO - allennlp.training.trainer - Epoch duration: 0:05:26.488938
2022-05-07 11:58:02,187 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:12:49
2022-05-07 11:58:02,187 - INFO - allennlp.training.trainer - Epoch 2/4
2022-05-07 11:58:02,188 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4297.04
2022-05-07 11:58:02,324 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7845
2022-05-07 11:58:02,332 - INFO - allennlp.training.trainer - Training
  0%|          | 0/832 [00:00<?, ?it/s]
.run/deps/UAS: 0.6605, .run/deps/LAS: 0.5756, .run/deps/UEM: 0.0203, .run/deps/LEM: 0.0145, .run/.sum: 1.2362, loss: 1.6198 ||:   3%|2         | 22/832 [00:10<06:19,  2.14it/s]
.run/deps/UAS: 0.6930, .run/deps/LAS: 0.6018, .run/deps/UEM: 0.0400, .run/deps/LEM: 0.0146, .run/.sum: 1.2948, loss: 1.4811 ||:   6%|6         | 52/832 [00:20<05:00,  2.60it/s]
.run/deps/UAS: 0.7026, .run/deps/LAS: 0.6117, .run/deps/UEM: 0.0376, .run/deps/LEM: 0.0138, .run/.sum: 1.3144, loss: 1.4671 ||:  10%|9         | 82/832 [00:32<04:57,  2.52it/s]
.run/deps/UAS: 0.7120, .run/deps/LAS: 0.6211, .run/deps/UEM: 0.0467, .run/deps/LEM: 0.0144, .run/.sum: 1.3331, loss: 1.4376 ||:  13%|#3        | 109/832 [00:43<04:42,  2.56it/s]
.run/deps/UAS: 0.7153, .run/deps/LAS: 0.6237, .run/deps/UEM: 0.0521, .run/deps/LEM: 0.0166, .run/.sum: 1.3391, loss: 1.4293 ||:  16%|#6        | 136/832 [00:53<04:31,  2.57it/s]
.run/deps/UAS: 0.7186, .run/deps/LAS: 0.6272, .run/deps/UEM: 0.0592, .run/deps/LEM: 0.0185, .run/.sum: 1.3458, loss: 1.4104 ||:  20%|#9        | 163/832 [01:03<04:18,  2.59it/s]
.run/deps/UAS: 0.7200, .run/deps/LAS: 0.6278, .run/deps/UEM: 0.0614, .run/deps/LEM: 0.0180, .run/.sum: 1.3478, loss: 1.4101 ||:  23%|##2       | 191/832 [01:14<04:03,  2.63it/s]
.run/deps/UAS: 0.7220, .run/deps/LAS: 0.6295, .run/deps/UEM: 0.0626, .run/deps/LEM: 0.0180, .run/.sum: 1.3515, loss: 1.4066 ||:  26%|##6       | 219/832 [01:25<03:55,  2.60it/s]
.run/deps/UAS: 0.7229, .run/deps/LAS: 0.6305, .run/deps/UEM: 0.0608, .run/deps/LEM: 0.0171, .run/.sum: 1.3534, loss: 1.4066 ||:  29%|##9       | 245/832 [01:35<03:47,  2.58it/s]
.run/deps/UAS: 0.7261, .run/deps/LAS: 0.6334, .run/deps/UEM: 0.0612, .run/deps/LEM: 0.0175, .run/.sum: 1.3595, loss: 1.3968 ||:  33%|###3      | 275/832 [01:45<03:26,  2.69it/s]
.run/deps/UAS: 0.7274, .run/deps/LAS: 0.6344, .run/deps/UEM: 0.0587, .run/deps/LEM: 0.0168, .run/.sum: 1.3618, loss: 1.3961 ||:  37%|###6      | 305/832 [01:56<03:12,  2.74it/s]
.run/deps/UAS: 0.7281, .run/deps/LAS: 0.6349, .run/deps/UEM: 0.0581, .run/deps/LEM: 0.0169, .run/.sum: 1.3630, loss: 1.3978 ||:  40%|####      | 334/832 [02:06<03:00,  2.76it/s]
.run/deps/UAS: 0.7290, .run/deps/LAS: 0.6361, .run/deps/UEM: 0.0588, .run/deps/LEM: 0.0167, .run/.sum: 1.3651, loss: 1.3927 ||:  44%|####3     | 363/832 [02:16<02:49,  2.77it/s]
.run/deps/UAS: 0.7299, .run/deps/LAS: 0.6372, .run/deps/UEM: 0.0611, .run/deps/LEM: 0.0179, .run/.sum: 1.3671, loss: 1.3873 ||:  47%|####6     | 391/832 [02:26<02:39,  2.77it/s]
.run/deps/UAS: 0.7304, .run/deps/LAS: 0.6379, .run/deps/UEM: 0.0621, .run/deps/LEM: 0.0185, .run/.sum: 1.3683, loss: 1.3856 ||:  50%|#####     | 420/832 [02:37<02:28,  2.78it/s]
.run/deps/UAS: 0.7300, .run/deps/LAS: 0.6377, .run/deps/UEM: 0.0617, .run/deps/LEM: 0.0187, .run/.sum: 1.3678, loss: 1.3853 ||:  54%|#####3    | 449/832 [02:48<02:20,  2.73it/s]
.run/deps/UAS: 0.7313, .run/deps/LAS: 0.6392, .run/deps/UEM: 0.0627, .run/deps/LEM: 0.0187, .run/.sum: 1.3705, loss: 1.3806 ||:  58%|#####7    | 479/832 [02:58<02:06,  2.80it/s]
.run/deps/UAS: 0.7322, .run/deps/LAS: 0.6402, .run/deps/UEM: 0.0640, .run/deps/LEM: 0.0192, .run/.sum: 1.3723, loss: 1.3771 ||:  61%|######1   | 509/832 [03:09<01:54,  2.81it/s]
.run/deps/UAS: 0.7332, .run/deps/LAS: 0.6413, .run/deps/UEM: 0.0641, .run/deps/LEM: 0.0192, .run/.sum: 1.3746, loss: 1.3732 ||:  65%|######4   | 538/832 [03:19<01:44,  2.83it/s]
.run/deps/UAS: 0.7349, .run/deps/LAS: 0.6430, .run/deps/UEM: 0.0649, .run/deps/LEM: 0.0191, .run/.sum: 1.3778, loss: 1.3668 ||:  68%|######8   | 567/832 [03:30<01:36,  2.74it/s]
.run/deps/UAS: 0.7352, .run/deps/LAS: 0.6436, .run/deps/UEM: 0.0639, .run/deps/LEM: 0.0185, .run/.sum: 1.3788, loss: 1.3639 ||:  71%|#######1  | 593/832 [03:40<01:28,  2.70it/s]
.run/deps/UAS: 0.7359, .run/deps/LAS: 0.6445, .run/deps/UEM: 0.0645, .run/deps/LEM: 0.0189, .run/.sum: 1.3804, loss: 1.3619 ||:  75%|#######4  | 621/832 [03:50<01:17,  2.73it/s]
.run/deps/UAS: 0.7368, .run/deps/LAS: 0.6453, .run/deps/UEM: 0.0641, .run/deps/LEM: 0.0186, .run/.sum: 1.3822, loss: 1.3580 ||:  78%|#######8  | 650/832 [04:00<01:06,  2.76it/s]
.run/deps/UAS: 0.7377, .run/deps/LAS: 0.6464, .run/deps/UEM: 0.0659, .run/deps/LEM: 0.0196, .run/.sum: 1.3842, loss: 1.3539 ||:  82%|########1 | 679/832 [04:10<00:54,  2.80it/s]
.run/deps/UAS: 0.7380, .run/deps/LAS: 0.6466, .run/deps/UEM: 0.0655, .run/deps/LEM: 0.0196, .run/.sum: 1.3846, loss: 1.3533 ||:  85%|########5 | 708/832 [04:21<00:44,  2.76it/s]
.run/deps/UAS: 0.7391, .run/deps/LAS: 0.6477, .run/deps/UEM: 0.0671, .run/deps/LEM: 0.0204, .run/.sum: 1.3867, loss: 1.3478 ||:  89%|########8 | 737/832 [04:31<00:34,  2.77it/s]
.run/deps/UAS: 0.7404, .run/deps/LAS: 0.6492, .run/deps/UEM: 0.0682, .run/deps/LEM: 0.0207, .run/.sum: 1.3896, loss: 1.3414 ||:  92%|#########2| 766/832 [04:41<00:23,  2.81it/s]
.run/deps/UAS: 0.7407, .run/deps/LAS: 0.6496, .run/deps/UEM: 0.0690, .run/deps/LEM: 0.0207, .run/.sum: 1.3903, loss: 1.3417 ||:  96%|#########5| 796/832 [04:52<00:12,  2.85it/s]
.run/deps/UAS: 0.7415, .run/deps/LAS: 0.6506, .run/deps/UEM: 0.0697, .run/deps/LEM: 0.0211, .run/.sum: 1.3921, loss: 1.3388 ||:  99%|#########9| 826/832 [05:02<00:02,  2.85it/s]
.run/deps/UAS: 0.7418, .run/deps/LAS: 0.6508, .run/deps/UEM: 0.0697, .run/deps/LEM: 0.0212, .run/.sum: 1.3926, loss: 1.3383 ||: 100%|##########| 832/832 [05:04<00:00,  2.73it/s]

2022-05-07 12:03:07,054 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/104 [00:00<?, ?it/s]
.run/deps/UAS: 0.9024, .run/deps/LAS: 0.8480, .run/deps/UEM: 0.3396, .run/deps/LEM: 0.1629, .run/.sum: 1.7504, loss: 0.5582 ||:  84%|########3 | 87/104 [00:10<00:01,  8.60it/s]
.run/deps/UAS: 0.8953, .run/deps/LAS: 0.8415, .run/deps/UEM: 0.2905, .run/deps/LEM: 0.1386, .run/.sum: 1.7368, loss: 0.5782 ||: 100%|##########| 104/104 [00:14<00:00,  7.22it/s]

2022-05-07 12:03:21,461 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2022-05-07 12:03:21,461 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS   |     0.742  |     0.895
2022-05-07 12:03:21,462 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4297.040  |       N/A
2022-05-07 12:03:21,463 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM   |     0.070  |     0.291
2022-05-07 12:03:21,464 - INFO - allennlp.training.tensorboard_writer - loss            |     1.338  |     0.578
2022-05-07 12:03:21,464 - INFO - allennlp.training.tensorboard_writer - .run/.sum       |     1.393  |     1.737
2022-05-07 12:03:21,465 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS   |     0.651  |     0.841
2022-05-07 12:03:21,466 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7845.000  |       N/A
2022-05-07 12:03:21,466 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM   |     0.021  |     0.139
2022-05-07 12:03:21,470 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2022-05-07 12:03:28,695 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/hindi_pretrained/2022.05.07_11.48.34/best.th'.
2022-05-07 12:03:31,128 - INFO - allennlp.training.trainer - Epoch duration: 0:05:28.940016
2022-05-07 12:03:31,128 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:21
2022-05-07 12:03:31,128 - INFO - allennlp.training.trainer - Epoch 3/4
2022-05-07 12:03:31,128 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4297.04
2022-05-07 12:03:31,256 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7845
2022-05-07 12:03:31,266 - INFO - allennlp.training.trainer - Training
  0%|          | 0/832 [00:00<?, ?it/s]
.run/deps/UAS: 0.7108, .run/deps/LAS: 0.6241, .run/deps/UEM: 0.0901, .run/deps/LEM: 0.0291, .run/.sum: 1.3349, loss: 1.3870 ||:   3%|2         | 22/832 [00:10<06:24,  2.11it/s]
.run/deps/UAS: 0.7423, .run/deps/LAS: 0.6548, .run/deps/UEM: 0.0895, .run/deps/LEM: 0.0289, .run/.sum: 1.3970, loss: 1.2664 ||:   6%|5         | 48/832 [00:20<05:33,  2.35it/s]
.run/deps/UAS: 0.7460, .run/deps/LAS: 0.6592, .run/deps/UEM: 0.0884, .run/deps/LEM: 0.0332, .run/.sum: 1.4051, loss: 1.2717 ||:   9%|8         | 74/832 [00:30<05:11,  2.43it/s]
.run/deps/UAS: 0.7499, .run/deps/LAS: 0.6623, .run/deps/UEM: 0.0886, .run/deps/LEM: 0.0320, .run/.sum: 1.4122, loss: 1.2574 ||:  12%|#2        | 100/832 [00:41<04:55,  2.47it/s]
.run/deps/UAS: 0.7530, .run/deps/LAS: 0.6647, .run/deps/UEM: 0.0846, .run/deps/LEM: 0.0302, .run/.sum: 1.4176, loss: 1.2666 ||:  16%|#5        | 129/832 [00:51<04:30,  2.60it/s]
.run/deps/UAS: 0.7551, .run/deps/LAS: 0.6670, .run/deps/UEM: 0.0869, .run/deps/LEM: 0.0306, .run/.sum: 1.4220, loss: 1.2664 ||:  19%|#8        | 158/832 [01:01<04:10,  2.69it/s]
.run/deps/UAS: 0.7569, .run/deps/LAS: 0.6693, .run/deps/UEM: 0.0851, .run/deps/LEM: 0.0315, .run/.sum: 1.4262, loss: 1.2600 ||:  22%|##2       | 187/832 [01:12<04:01,  2.67it/s]
.run/deps/UAS: 0.7597, .run/deps/LAS: 0.6720, .run/deps/UEM: 0.0861, .run/deps/LEM: 0.0331, .run/.sum: 1.4317, loss: 1.2526 ||:  26%|##5       | 216/832 [01:22<03:46,  2.71it/s]
.run/deps/UAS: 0.7594, .run/deps/LAS: 0.6713, .run/deps/UEM: 0.0852, .run/deps/LEM: 0.0318, .run/.sum: 1.4307, loss: 1.2574 ||:  29%|##9       | 244/832 [01:33<03:38,  2.69it/s]
.run/deps/UAS: 0.7596, .run/deps/LAS: 0.6711, .run/deps/UEM: 0.0862, .run/deps/LEM: 0.0307, .run/.sum: 1.4307, loss: 1.2612 ||:  33%|###2      | 271/832 [01:44<03:35,  2.60it/s]
.run/deps/UAS: 0.7595, .run/deps/LAS: 0.6714, .run/deps/UEM: 0.0876, .run/deps/LEM: 0.0317, .run/.sum: 1.4309, loss: 1.2575 ||:  36%|###5      | 296/832 [01:54<03:28,  2.57it/s]
.run/deps/UAS: 0.7608, .run/deps/LAS: 0.6723, .run/deps/UEM: 0.0867, .run/deps/LEM: 0.0307, .run/.sum: 1.4330, loss: 1.2528 ||:  39%|###8      | 324/832 [02:04<03:13,  2.63it/s]
.run/deps/UAS: 0.7625, .run/deps/LAS: 0.6740, .run/deps/UEM: 0.0855, .run/deps/LEM: 0.0302, .run/.sum: 1.4364, loss: 1.2476 ||:  42%|####2     | 352/832 [02:15<03:00,  2.66it/s]
.run/deps/UAS: 0.7625, .run/deps/LAS: 0.6740, .run/deps/UEM: 0.0856, .run/deps/LEM: 0.0306, .run/.sum: 1.4364, loss: 1.2496 ||:  46%|####5     | 380/832 [02:25<02:48,  2.69it/s]
.run/deps/UAS: 0.7637, .run/deps/LAS: 0.6749, .run/deps/UEM: 0.0863, .run/deps/LEM: 0.0308, .run/.sum: 1.4386, loss: 1.2432 ||:  49%|####9     | 409/832 [02:35<02:35,  2.73it/s]
.run/deps/UAS: 0.7630, .run/deps/LAS: 0.6746, .run/deps/UEM: 0.0853, .run/deps/LEM: 0.0297, .run/.sum: 1.4376, loss: 1.2444 ||:  53%|#####2    | 438/832 [02:46<02:23,  2.74it/s]
.run/deps/UAS: 0.7633, .run/deps/LAS: 0.6748, .run/deps/UEM: 0.0854, .run/deps/LEM: 0.0295, .run/.sum: 1.4380, loss: 1.2430 ||:  56%|#####6    | 468/832 [02:56<02:10,  2.80it/s]
.run/deps/UAS: 0.7639, .run/deps/LAS: 0.6753, .run/deps/UEM: 0.0867, .run/deps/LEM: 0.0300, .run/.sum: 1.4392, loss: 1.2410 ||:  60%|#####9    | 498/832 [03:06<01:58,  2.83it/s]
.run/deps/UAS: 0.7650, .run/deps/LAS: 0.6762, .run/deps/UEM: 0.0861, .run/deps/LEM: 0.0292, .run/.sum: 1.4412, loss: 1.2400 ||:  63%|######3   | 527/832 [03:17<01:48,  2.82it/s]
.run/deps/UAS: 0.7661, .run/deps/LAS: 0.6768, .run/deps/UEM: 0.0849, .run/deps/LEM: 0.0293, .run/.sum: 1.4429, loss: 1.2375 ||:  67%|######6   | 557/832 [03:27<01:36,  2.85it/s]
.run/deps/UAS: 0.7665, .run/deps/LAS: 0.6773, .run/deps/UEM: 0.0858, .run/deps/LEM: 0.0298, .run/.sum: 1.4438, loss: 1.2372 ||:  71%|#######   | 587/832 [03:37<01:25,  2.87it/s]
.run/deps/UAS: 0.7671, .run/deps/LAS: 0.6780, .run/deps/UEM: 0.0867, .run/deps/LEM: 0.0294, .run/.sum: 1.4451, loss: 1.2333 ||:  74%|#######4  | 617/832 [03:48<01:15,  2.83it/s]
.run/deps/UAS: 0.7682, .run/deps/LAS: 0.6794, .run/deps/UEM: 0.0879, .run/deps/LEM: 0.0300, .run/.sum: 1.4476, loss: 1.2271 ||:  78%|#######7  | 646/832 [03:58<01:05,  2.82it/s]
.run/deps/UAS: 0.7688, .run/deps/LAS: 0.6801, .run/deps/UEM: 0.0873, .run/deps/LEM: 0.0296, .run/.sum: 1.4488, loss: 1.2240 ||:  81%|########1 | 675/832 [04:10<00:57,  2.73it/s]
.run/deps/UAS: 0.7695, .run/deps/LAS: 0.6807, .run/deps/UEM: 0.0883, .run/deps/LEM: 0.0300, .run/.sum: 1.4502, loss: 1.2199 ||:  84%|########4 | 702/832 [04:20<00:48,  2.71it/s]
.run/deps/UAS: 0.7697, .run/deps/LAS: 0.6812, .run/deps/UEM: 0.0890, .run/deps/LEM: 0.0306, .run/.sum: 1.4509, loss: 1.2174 ||:  88%|########7 | 729/832 [04:31<00:38,  2.65it/s]
.run/deps/UAS: 0.7704, .run/deps/LAS: 0.6817, .run/deps/UEM: 0.0891, .run/deps/LEM: 0.0305, .run/.sum: 1.4521, loss: 1.2137 ||:  91%|#########1| 758/832 [04:41<00:27,  2.70it/s]
.run/deps/UAS: 0.7710, .run/deps/LAS: 0.6826, .run/deps/UEM: 0.0886, .run/deps/LEM: 0.0300, .run/.sum: 1.4535, loss: 1.2107 ||:  95%|#########4| 787/832 [04:53<00:17,  2.61it/s]
.run/deps/UAS: 0.7708, .run/deps/LAS: 0.6825, .run/deps/UEM: 0.0883, .run/deps/LEM: 0.0298, .run/.sum: 1.4534, loss: 1.2107 ||:  98%|#########7| 812/832 [05:03<00:07,  2.56it/s]
.run/deps/UAS: 0.7705, .run/deps/LAS: 0.6822, .run/deps/UEM: 0.0889, .run/deps/LEM: 0.0303, .run/.sum: 1.4527, loss: 1.2125 ||: 100%|##########| 832/832 [05:11<00:00,  2.67it/s]

2022-05-07 12:08:43,034 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/104 [00:00<?, ?it/s]
.run/deps/UAS: 0.9178, .run/deps/LAS: 0.8671, .run/deps/UEM: 0.4173, .run/deps/LEM: 0.2110, .run/.sum: 1.7849, loss: 0.4892 ||:  77%|#######6  | 80/104 [00:10<00:03,  7.95it/s]
.run/deps/UAS: 0.9079, .run/deps/LAS: 0.8565, .run/deps/UEM: 0.3400, .run/deps/LEM: 0.1658, .run/.sum: 1.7644, loss: 0.5194 ||: 100%|##########| 104/104 [00:16<00:00,  6.39it/s]

2022-05-07 12:08:59,321 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2022-05-07 12:08:59,322 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS   |     0.770  |     0.908
2022-05-07 12:08:59,323 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4297.040  |       N/A
2022-05-07 12:08:59,324 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM   |     0.089  |     0.340
2022-05-07 12:08:59,325 - INFO - allennlp.training.tensorboard_writer - loss            |     1.213  |     0.519
2022-05-07 12:08:59,326 - INFO - allennlp.training.tensorboard_writer - .run/.sum       |     1.453  |     1.764
2022-05-07 12:08:59,326 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS   |     0.682  |     0.857
2022-05-07 12:08:59,327 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7845.000  |       N/A
2022-05-07 12:08:59,328 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM   |     0.030  |     0.166
2022-05-07 12:08:59,348 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2022-05-07 12:09:06,599 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/hindi_pretrained/2022.05.07_11.48.34/best.th'.
2022-05-07 12:09:09,025 - INFO - allennlp.training.trainer - Epoch duration: 0:05:37.896457
2022-05-07 12:09:09,025 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:54
2022-05-07 12:09:09,025 - INFO - allennlp.training.trainer - Epoch 4/4
2022-05-07 12:09:09,025 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4297.156
2022-05-07 12:09:09,134 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 7845
2022-05-07 12:09:09,143 - INFO - allennlp.training.trainer - Training
  0%|          | 0/832 [00:00<?, ?it/s]
.run/deps/UAS: 0.7531, .run/deps/LAS: 0.6734, .run/deps/UEM: 0.0988, .run/deps/LEM: 0.0349, .run/.sum: 1.4265, loss: 1.1810 ||:   3%|2         | 22/832 [00:10<06:14,  2.16it/s]
.run/deps/UAS: 0.7738, .run/deps/LAS: 0.6924, .run/deps/UEM: 0.1158, .run/deps/LEM: 0.0329, .run/.sum: 1.4662, loss: 1.1389 ||:   6%|5         | 48/832 [00:20<05:33,  2.35it/s]
.run/deps/UAS: 0.7736, .run/deps/LAS: 0.6912, .run/deps/UEM: 0.1198, .run/deps/LEM: 0.0379, .run/.sum: 1.4648, loss: 1.1567 ||:   9%|8         | 73/832 [00:30<05:16,  2.40it/s]
.run/deps/UAS: 0.7779, .run/deps/LAS: 0.6961, .run/deps/UEM: 0.1133, .run/deps/LEM: 0.0333, .run/.sum: 1.4740, loss: 1.1500 ||:  12%|#2        | 102/832 [00:40<04:41,  2.59it/s]
.run/deps/UAS: 0.7829, .run/deps/LAS: 0.7007, .run/deps/UEM: 0.1202, .run/deps/LEM: 0.0361, .run/.sum: 1.4836, loss: 1.1309 ||:  16%|#5        | 132/832 [00:50<04:16,  2.73it/s]
.run/deps/UAS: 0.7837, .run/deps/LAS: 0.7015, .run/deps/UEM: 0.1188, .run/deps/LEM: 0.0368, .run/.sum: 1.4852, loss: 1.1250 ||:  19%|#9        | 162/832 [01:01<04:01,  2.77it/s]
.run/deps/UAS: 0.7833, .run/deps/LAS: 0.7003, .run/deps/UEM: 0.1129, .run/deps/LEM: 0.0354, .run/.sum: 1.4836, loss: 1.1311 ||:  23%|##2       | 191/832 [01:11<03:51,  2.76it/s]
.run/deps/UAS: 0.7825, .run/deps/LAS: 0.6994, .run/deps/UEM: 0.1113, .run/deps/LEM: 0.0349, .run/.sum: 1.4819, loss: 1.1336 ||:  26%|##6       | 219/832 [01:22<03:41,  2.77it/s]
.run/deps/UAS: 0.7812, .run/deps/LAS: 0.6980, .run/deps/UEM: 0.1093, .run/deps/LEM: 0.0347, .run/.sum: 1.4792, loss: 1.1416 ||:  30%|##9       | 247/832 [01:32<03:33,  2.74it/s]
.run/deps/UAS: 0.7814, .run/deps/LAS: 0.6978, .run/deps/UEM: 0.1097, .run/deps/LEM: 0.0352, .run/.sum: 1.4791, loss: 1.1419 ||:  33%|###2      | 274/832 [01:43<03:27,  2.69it/s]
.run/deps/UAS: 0.7815, .run/deps/LAS: 0.6977, .run/deps/UEM: 0.1105, .run/deps/LEM: 0.0351, .run/.sum: 1.4792, loss: 1.1429 ||:  36%|###6      | 303/832 [01:53<03:15,  2.71it/s]
.run/deps/UAS: 0.7814, .run/deps/LAS: 0.6975, .run/deps/UEM: 0.1091, .run/deps/LEM: 0.0352, .run/.sum: 1.4789, loss: 1.1444 ||:  40%|###9      | 331/832 [02:04<03:09,  2.64it/s]
.run/deps/UAS: 0.7818, .run/deps/LAS: 0.6976, .run/deps/UEM: 0.1110, .run/deps/LEM: 0.0356, .run/.sum: 1.4795, loss: 1.1431 ||:  43%|####2     | 357/832 [02:14<03:01,  2.61it/s]
.run/deps/UAS: 0.7826, .run/deps/LAS: 0.6978, .run/deps/UEM: 0.1107, .run/deps/LEM: 0.0359, .run/.sum: 1.4804, loss: 1.1426 ||:  46%|####6     | 384/832 [02:25<02:51,  2.62it/s]
.run/deps/UAS: 0.7828, .run/deps/LAS: 0.6980, .run/deps/UEM: 0.1098, .run/deps/LEM: 0.0353, .run/.sum: 1.4808, loss: 1.1431 ||:  49%|####9     | 411/832 [02:36<02:42,  2.58it/s]
.run/deps/UAS: 0.7833, .run/deps/LAS: 0.6986, .run/deps/UEM: 0.1092, .run/deps/LEM: 0.0361, .run/.sum: 1.4819, loss: 1.1422 ||:  53%|#####2    | 437/832 [02:46<02:32,  2.59it/s]
.run/deps/UAS: 0.7834, .run/deps/LAS: 0.6984, .run/deps/UEM: 0.1072, .run/deps/LEM: 0.0346, .run/.sum: 1.4818, loss: 1.1451 ||:  56%|#####5    | 463/832 [02:56<02:24,  2.56it/s]
.run/deps/UAS: 0.7831, .run/deps/LAS: 0.6980, .run/deps/UEM: 0.1064, .run/deps/LEM: 0.0352, .run/.sum: 1.4811, loss: 1.1461 ||:  59%|#####8    | 490/832 [03:06<02:11,  2.59it/s]
.run/deps/UAS: 0.7836, .run/deps/LAS: 0.6984, .run/deps/UEM: 0.1052, .run/deps/LEM: 0.0357, .run/.sum: 1.4820, loss: 1.1444 ||:  62%|######2   | 518/832 [03:16<01:59,  2.63it/s]
.run/deps/UAS: 0.7841, .run/deps/LAS: 0.6987, .run/deps/UEM: 0.1048, .run/deps/LEM: 0.0357, .run/.sum: 1.4828, loss: 1.1440 ||:  66%|######5   | 547/832 [03:26<01:45,  2.71it/s]
.run/deps/UAS: 0.7840, .run/deps/LAS: 0.6986, .run/deps/UEM: 0.1065, .run/deps/LEM: 0.0371, .run/.sum: 1.4826, loss: 1.1446 ||:  69%|######9   | 576/832 [03:37<01:34,  2.71it/s]
.run/deps/UAS: 0.7842, .run/deps/LAS: 0.6990, .run/deps/UEM: 0.1055, .run/deps/LEM: 0.0366, .run/.sum: 1.4832, loss: 1.1441 ||:  73%|#######2  | 604/832 [03:49<01:27,  2.62it/s]
.run/deps/UAS: 0.7843, .run/deps/LAS: 0.6991, .run/deps/UEM: 0.1058, .run/deps/LEM: 0.0367, .run/.sum: 1.4834, loss: 1.1439 ||:  76%|#######6  | 633/832 [03:59<01:14,  2.67it/s]
.run/deps/UAS: 0.7846, .run/deps/LAS: 0.6994, .run/deps/UEM: 0.1061, .run/deps/LEM: 0.0368, .run/.sum: 1.4840, loss: 1.1434 ||:  80%|#######9  | 662/832 [04:09<01:02,  2.72it/s]
.run/deps/UAS: 0.7848, .run/deps/LAS: 0.6996, .run/deps/UEM: 0.1045, .run/deps/LEM: 0.0363, .run/.sum: 1.4844, loss: 1.1418 ||:  83%|########3 | 691/832 [04:19<00:51,  2.76it/s]
.run/deps/UAS: 0.7852, .run/deps/LAS: 0.7000, .run/deps/UEM: 0.1038, .run/deps/LEM: 0.0363, .run/.sum: 1.4852, loss: 1.1395 ||:  87%|########6 | 720/832 [04:30<00:40,  2.76it/s]
.run/deps/UAS: 0.7849, .run/deps/LAS: 0.6995, .run/deps/UEM: 0.1028, .run/deps/LEM: 0.0361, .run/.sum: 1.4845, loss: 1.1415 ||:  90%|########9 | 748/832 [04:41<00:31,  2.68it/s]
.run/deps/UAS: 0.7856, .run/deps/LAS: 0.7001, .run/deps/UEM: 0.1053, .run/deps/LEM: 0.0369, .run/.sum: 1.4857, loss: 1.1386 ||:  93%|#########3| 775/832 [04:51<00:21,  2.66it/s]
.run/deps/UAS: 0.7863, .run/deps/LAS: 0.7009, .run/deps/UEM: 0.1053, .run/deps/LEM: 0.0369, .run/.sum: 1.4872, loss: 1.1360 ||:  96%|#########6| 802/832 [05:02<00:11,  2.63it/s]
.run/deps/UAS: 0.7866, .run/deps/LAS: 0.7011, .run/deps/UEM: 0.1061, .run/deps/LEM: 0.0368, .run/.sum: 1.4878, loss: 1.1342 ||: 100%|#########9| 829/832 [05:12<00:01,  2.63it/s]
.run/deps/UAS: 0.7868, .run/deps/LAS: 0.7013, .run/deps/UEM: 0.1061, .run/deps/LEM: 0.0368, .run/.sum: 1.4881, loss: 1.1334 ||: 100%|##########| 832/832 [05:13<00:00,  2.65it/s]

2022-05-07 12:14:22,733 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/104 [00:00<?, ?it/s]
.run/deps/UAS: 0.9204, .run/deps/LAS: 0.8712, .run/deps/UEM: 0.4141, .run/deps/LEM: 0.2124, .run/.sum: 1.7916, loss: 0.4754 ||:  85%|########4 | 88/104 [00:10<00:01,  8.67it/s]
.run/deps/UAS: 0.9151, .run/deps/LAS: 0.8658, .run/deps/UEM: 0.3629, .run/deps/LEM: 0.1826, .run/.sum: 1.7808, loss: 0.4910 ||: 100%|##########| 104/104 [00:14<00:00,  7.37it/s]

2022-05-07 12:14:36,845 - INFO - allennlp.training.tensorboard_writer -                     Training |  Validation
2022-05-07 12:14:36,846 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS   |     0.787  |     0.915
2022-05-07 12:14:36,848 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB   |  4297.156  |       N/A
2022-05-07 12:14:36,849 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM   |     0.106  |     0.363
2022-05-07 12:14:36,850 - INFO - allennlp.training.tensorboard_writer - loss            |     1.133  |     0.491
2022-05-07 12:14:36,850 - INFO - allennlp.training.tensorboard_writer - .run/.sum       |     1.488  |     1.781
2022-05-07 12:14:36,851 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS   |     0.701  |     0.866
2022-05-07 12:14:36,852 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB |  7845.000  |       N/A
2022-05-07 12:14:36,852 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM   |     0.037  |     0.183
2022-05-07 12:14:36,856 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2022-05-07 12:14:44,103 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/hindi_pretrained/2022.05.07_11.48.34/best.th'.
2022-05-07 12:14:46,538 - INFO - allennlp.training.trainer - Epoch duration: 0:05:37.513000
2022-05-07 12:14:46,542 - INFO - allennlp.training.checkpointer - loading best weights
2022-05-07 12:14:47,599 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2022-05-07 12:14:47,601 - INFO - allennlp.training.util - Iterating over dataset
  0%|          | 0/106 [00:00<?, ?it/s]
.run/deps/UAS: 0.92, .run/deps/LAS: 0.87, .run/deps/UEM: 0.44, .run/deps/LEM: 0.23, .run/.sum: 1.80, loss: 0.46 ||:  82%|########2 | 87/106 [00:10<00:02,  8.65it/s]
.run/deps/UAS: 0.92, .run/deps/LAS: 0.87, .run/deps/UEM: 0.38, .run/deps/LEM: 0.19, .run/.sum: 1.78, loss: 0.49 ||: 100%|##########| 106/106 [00:14<00:00,  7.31it/s]

2022-05-07 12:15:02,110 - INFO - allennlp.models.archival - archiving weights and vocabulary to logs/hindi_pretrained/2022.05.07_11.48.34/model.tar.gz
2022-05-07 12:16:13,800 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 4,
  "peak_cpu_memory_MB": 4297.156,
  "peak_gpu_0_memory_MB": 7845,
  "training_duration": "0:25:07.485057",
  "training_start_epoch": 0,
  "training_epochs": 4,
  "epoch": 4,
  "training_.run/deps/UAS": 0.7868012538381894,
  "training_.run/deps/LAS": 0.7013346047243086,
  "training_.run/deps/UEM": 0.10613349368610944,
  "training_.run/deps/LEM": 0.03675586289837643,
  "training_.run/.sum": 1.4881358585624982,
  "training_loss": 1.1333899207843037,
  "training_cpu_memory_MB": 4297.156,
  "training_gpu_0_memory_MB": 7845,
  "validation_.run/deps/UAS": 0.9150694266973337,
  "validation_.run/deps/LAS": 0.8657750518215634,
  "validation_.run/deps/UEM": 0.3628691983122363,
  "validation_.run/deps/LEM": 0.18264014466546113,
  "validation_.run/.sum": 1.780844478518897,
  "validation_loss": 0.4909932260903028,
  "best_validation_.run/deps/UAS": 0.9150694266973337,
  "best_validation_.run/deps/LAS": 0.8657750518215634,
  "best_validation_.run/deps/UEM": 0.3628691983122363,
  "best_validation_.run/deps/LEM": 0.18264014466546113,
  "best_validation_.run/.sum": 1.780844478518897,
  "best_validation_loss": 0.4909932260903028,
  "test_.run/deps/UAS": 0.9155235675980807,
  "test_.run/deps/LAS": 0.8668360146768276,
  "test_.run/deps/UEM": 0.37885985748218526,
  "test_.run/deps/LEM": 0.18883610451306412,
  "test_.run/.sum": 1.7823595822749083,
  "test_loss": 0.49046636260343046
}
Starting with seed 1
data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-train.conllu
1841
data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-dev.conllu
217
data/ud-treebanks-v2.3/UD_Hindi-HDTB/hi_hdtb-ud-test.conllu
211
All training is done. EXITING AFTER CLEARNING UP
AFTER CLEARNING UP. EXIING
